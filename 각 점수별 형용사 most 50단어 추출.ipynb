{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"reviews_Books_5.json\",\"r\") as data_file:\n",
    "    raw_data=data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"AAXUNK0W2DZG5\", \"asin\": \"0060520841\", \"reviewerName\": \"Amazon Customer \\\"leneker\\\"\", \"helpful\": [5, 10], \"reviewText\": \"1996 Bernard Goldberg wrote an editorial for the Wall Street Journal that said there was an obvious bias on the part of network new shows  for the liberal point of view.  he then illustrated this with an example that he dissected in-depth.  The reaction to this observation was the ruination of her career, and the beginning of his status as a pariah among most newsmen.  This book is used to add more ammo to the controversy.That the journalists who so eagerly pry into other peoples lives and business should be reluctant to be examined is hardly surprising.  Almost no one really wants to have his life or business dissected by Mike Wallace not even Dan Rather.  Some facts in this book are really potent such as the survey results which show how the average journalist and the average American are often vastly at odds.  Other chapters highlight different stories that TV news has covered and the analysis that Goldberg has made to point out the liberal bias.  His main theme is that while there is no conspiracy of the left, the fact is that most reporters are liberal but fewer still will admit it.There is some sound reasoning behind this book.  Sadly in execution, it doesn't come off as well as it could.  Goldberg has one argument in all the years he worked closely with Dan Rather (according to him) and yet it seems like all they did was fight.  Why ?  because Goldberg replays that one argument about 5 or 6 times in the book.  Much of the material that is thought provoking the first time around is pretty stale after the third or fourth reading. He kindly reprints the editorial that started the whole furor, too bad this was at the end of the book because the entire first chapter is just a rehash of that argument.  Too often Goldberg is reduced sounding like the bitter vindictive perso 93184\n"
     ]
    }
   ],
   "source": [
    "json_list = []\n",
    "for i in range(len(raw_data)):\n",
    "    try:\n",
    "        json_data = json.loads(raw_data[i])\n",
    "        json_list.append(json_data)\n",
    "    except:\n",
    "        print(raw_data[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewText': 'Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!', 'reviewTime': '12 16, 2012', 'overall': 5.0, 'asin': '000100039X', 'summary': 'Wonderful!', 'reviewerName': 'Adam', 'helpful': [0, 0], 'reviewerID': 'A10000012B7CGYKOMPQ4L', 'unixReviewTime': 1355616000}\n"
     ]
    }
   ],
   "source": [
    "print(json_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = []\n",
    "\n",
    "for i in range(len(json_list)):\n",
    "    review_dict={}\n",
    "    review_dict[\"reviewText\"] = json_list[i][\"reviewText\"]\n",
    "    review_dict[\"overall\"] = json_list[i][\"overall\"]\n",
    "    review_data.append(review_dict)\n",
    "type(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 1.0,\n",
       " 'reviewText': 'Very disappointing last book. Had to force myself to finish and basically skimmed the last 30%. Trying to figure out whose voice we were reading got tedious. Nothing really happened. No real advance of story like the first one had.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_data = random.sample(review_data,len(review_data))\n",
    "random_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very disappointing last book. Had to force myself to finish and basically skimmed the last 30%. Trying to figure out whose voice we were reading got tedious. Nothing really happened. No real advance of story like the first one had.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data[0]['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one = []\n",
    "two = []\n",
    "three = []\n",
    "four = []\n",
    "five = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for x in random_data:\n",
    "    if x[\"overall\"] == 1.0:\n",
    "        one.append(x[\"reviewText\"])\n",
    "    elif x[\"overall\"] == 2.0:\n",
    "        two.append(x[\"reviewText\"])\n",
    "    elif x[\"overall\"] == 3.0:\n",
    "        three.append(x[\"reviewText\"])\n",
    "    elif x[\"overall\"] == 4.0:\n",
    "        four.append(x[\"reviewText\"])\n",
    "    else:\n",
    "        five.append(x[\"reviewText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samsung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 관사 접속사 제거\n",
    "stopword_one = []\n",
    "stopword_two = []\n",
    "stopword_three = []\n",
    "stopword_four = []\n",
    "stopword_five = []\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "for i in range(len(stemming_one)):\n",
    "    for j in stemming_one[i]:\n",
    "        if j not in stop:\n",
    "            stopword_one.append(j)\n",
    "for i in range(len(stemming_two)):\n",
    "    for j in stemming_two[i]:\n",
    "        if j not in stop:\n",
    "            stopword_two.append(j)\n",
    "for i in range(len(stemming_three)):\n",
    "    for j in stemming_three[i]:\n",
    "        if j not in stop:\n",
    "            stopword_three.append(j)\n",
    "for i in range(len(stemming_four)):\n",
    "    for j in stemming_four[i]:\n",
    "        if j not in stop:\n",
    "            stopword_four.append(j)\n",
    "for i in range(len(stemming_five)):\n",
    "    for j in stemming_five[i]:\n",
    "        if j not in stop:\n",
    "            stopword_five.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원형으로 변환해줌\n",
    "stemming_one = []\n",
    "stemming_two = []\n",
    "stemming_three = []\n",
    "stemming_four = []\n",
    "stemming_five = []\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "for i in range(len(one)):\n",
    "    stemming_one.append(tokenizer_porter(one[i]))\n",
    "    \n",
    "for i in range(len(two)):\n",
    "    try:\n",
    "        stemming_two.append(tokenizer_porter(two[i]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in range(len(three)):\n",
    "    try:\n",
    "        stemming_three.append(tokenizer_porter(three[i]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for i in range(len(four)):\n",
    "    try:\n",
    "        stemming_four.append(tokenizer_porter(four[i]))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "for i in range(len(five)):\n",
    "    try:\n",
    "        stemming_five.append(tokenizer_porter(five[i]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443445"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veri', 'disappoint', 'last', 'book.', 'forc', 'finish', 'basic', 'skim', 'last', '30%.']\n"
     ]
    }
   ],
   "source": [
    "print(stopword_one[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pos_tagging(document):\n",
    "    result = nltk.pos_tag( nltk.word_tokenize(document))    \n",
    "    last_result = ['/'.join(t) for t in result]\n",
    "    return last_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tag_one = [pos_tagging(one) for one in stopword_one]\n",
    "tag_two = [pos_tagging(two) for two in stopword_two]\n",
    "tag_three = [pos_tagging(three) for three in stopword_three]\n",
    "tag_four = [pos_tagging(four) for four in stopword_four]\n",
    "tag_five = [pos_tagging(five) for five in stopword_five]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tag_overall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "choose_tagging_texts1 = []\n",
    "choose_tagging_texts2 = []\n",
    "choose_tagging_texts3 = []\n",
    "choose_tagging_texts4 = []\n",
    "choose_tagging_texts5 = []\n",
    "\n",
    "for i in range(len(tag_one)):\n",
    "    for j in tag_one[i]:\n",
    "        if j.split(\"/\")[1] ==\"JJ\":\n",
    "            choose_tagging_texts1.append(j)\n",
    "\n",
    "for i in range(len(tag_two)):\n",
    "    for j in tag_two[i]:\n",
    "        if j.split(\"/\")[1] ==\"JJ\":\n",
    "            choose_tagging_texts2.append(j)\n",
    "\n",
    "for i in range(len(tag_three)):\n",
    "    for j in tag_three[i]:\n",
    "        if j.split(\"/\")[1] ==\"JJ\":\n",
    "            choose_tagging_texts3.append(j)\n",
    "            \n",
    "for i in range(len(tag_four)):\n",
    "    for j in tag_four[i]:\n",
    "        if j.split(\"/\")[1] ==\"JJ\":\n",
    "            choose_tagging_texts4.append(j)\n",
    "            \n",
    "for i in range(len(tag_five)):\n",
    "    for j in tag_five[i]:\n",
    "        if j.split(\"/\")[1] ==\"JJ\":\n",
    "            choose_tagging_texts5.append(j)\n",
    "            \n",
    "# 형용사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last/JJ', 'basic/JJ', 'last/JJ', 'tedious/JJ', 'real/JJ', 'whole/JJ', 'unread/JJ', 'last/JJ', 'third/JJ', 'great/JJ']\n"
     ]
    }
   ],
   "source": [
    "print(choose_tagging_texts1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good/JJ 1373\n",
      "much/JJ 1272\n",
      "bad/JJ 729\n",
      "great/JJ 708\n",
      "actual/JJ 653\n",
      "new/JJ 630\n",
      "last/JJ 561\n",
      "real/JJ 466\n",
      "main/JJ 446\n",
      "live/JJ 426\n",
      "whole/JJ 402\n",
      "old/JJ 399\n",
      "hard/JJ 366\n",
      "final/JJ 332\n",
      "next/JJ 329\n",
      "american/JJ 328\n",
      "wrong/JJ 317\n",
      "big/JJ 309\n",
      "true/JJ 275\n",
      "total/JJ 272\n",
      "short/JJ 266\n",
      "poor/JJ 252\n",
      "third/JJ 241\n",
      "second/JJ 232\n",
      "high/JJ 232\n",
      "young/JJ 207\n",
      "major/JJ 198\n",
      "basic/JJ 184\n",
      "stupid/JJ 180\n",
      "full/JJ 179\n",
      "usual/JJ 178\n",
      "white/JJ 172\n",
      "dead/JJ 156\n",
      "black/JJ 155\n",
      "free/JJ 149\n",
      "huge/JJ 143\n",
      "english/JJ 137\n",
      "open/JJ 134\n",
      "clear/JJ 127\n",
      "difficult/JJ 125\n",
      "strong/JJ 125\n",
      "complex/JJ 119\n",
      "modern/JJ 117\n",
      "weak/JJ 116\n",
      "flat/JJ 116\n",
      "obvious/JJ 115\n",
      "nice/JJ 111\n",
      "small/JJ 110\n",
      "classic/JJ 105\n",
      "certain/JJ 102\n",
      "moral/JJ 100\n",
      "recent/JJ 94\n",
      "other/JJ 92\n",
      "social/JJ 92\n",
      "popular/JJ 91\n",
      "practic/JJ 90\n",
      "particular/JJ 90\n",
      "german/JJ 88\n",
      "current/JJ 87\n",
      "similar/JJ 86\n",
      "normal/JJ 84\n",
      "british/JJ 83\n",
      "common/JJ 83\n",
      "serious/JJ 79\n",
      "sexual/JJ 77\n",
      "due/JJ 76\n",
      "rich/JJ 73\n",
      "equal/JJ 72\n",
      "notic/JJ 72\n",
      "hous/JJ 70\n",
      "low/JJ 67\n",
      "direct/JJ 66\n",
      "special/JJ 65\n",
      "western/JJ 63\n",
      "overal/JJ 63\n",
      "ridiculous/JJ 62\n",
      "french/JJ 61\n",
      "superior/JJ 60\n",
      "horrible/JJ 59\n",
      "local/JJ 58\n",
      "red/JJ 57\n",
      "terrible/JJ 54\n",
      "civil/JJ 52\n",
      "own/JJ 52\n",
      "same/JJ 52\n",
      "familiar/JJ 51\n",
      "factual/JJ 49\n",
      "former/JJ 48\n",
      "constant/JJ 48\n",
      "possible/JJ 47\n",
      "many/JJ 46\n",
      "tough/JJ 46\n",
      "republican/JJ 45\n",
      "central/JJ 45\n",
      "european/JJ 44\n",
      "hot/JJ 43\n",
      "tedious/JJ 42\n",
      "graphic/JJ 40\n",
      "dual/JJ 40\n",
      "soviet/JJ 40\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "choose_tagging_texts_one = Counter(choose_tagging_texts1)\n",
    "for word, count in choose_tagging_texts_one.most_common(100):\n",
    "    print(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "much/JJ 2166\n",
      "good/JJ 1958\n",
      "great/JJ 1031\n",
      "bad/JJ 747\n",
      "new/JJ 713\n",
      "actual/JJ 700\n",
      "last/JJ 683\n",
      "real/JJ 613\n",
      "main/JJ 606\n",
      "live/JJ 552\n",
      "hard/JJ 542\n",
      "next/JJ 495\n",
      "whole/JJ 489\n",
      "old/JJ 488\n",
      "final/JJ 449\n",
      "short/JJ 413\n",
      "second/JJ 398\n",
      "big/JJ 370\n",
      "true/JJ 336\n",
      "wrong/JJ 333\n",
      "high/JJ 316\n",
      "young/JJ 313\n",
      "american/JJ 305\n",
      "third/JJ 304\n",
      "major/JJ 289\n",
      "basic/JJ 245\n",
      "total/JJ 243\n",
      "poor/JJ 235\n",
      "difficult/JJ 234\n",
      "white/JJ 211\n",
      "usual/JJ 209\n",
      "black/JJ 192\n",
      "clear/JJ 191\n",
      "full/JJ 189\n",
      "huge/JJ 184\n",
      "strong/JJ 169\n",
      "nice/JJ 167\n",
      "flat/JJ 166\n",
      "classic/JJ 162\n",
      "small/JJ 161\n",
      "open/JJ 160\n",
      "obvious/JJ 157\n",
      "certain/JJ 156\n",
      "dead/JJ 155\n",
      "modern/JJ 155\n",
      "weak/JJ 152\n",
      "english/JJ 151\n",
      "stupid/JJ 142\n",
      "similar/JJ 139\n",
      "sexual/JJ 137\n",
      "particular/JJ 133\n",
      "free/JJ 132\n",
      "other/JJ 131\n",
      "overal/JJ 123\n",
      "hous/JJ 121\n",
      "due/JJ 120\n",
      "recent/JJ 118\n",
      "normal/JJ 117\n",
      "social/JJ 116\n",
      "popular/JJ 114\n",
      "british/JJ 113\n",
      "red/JJ 109\n",
      "moral/JJ 107\n",
      "rich/JJ 102\n",
      "common/JJ 101\n",
      "german/JJ 100\n",
      "equal/JJ 99\n",
      "complex/JJ 99\n",
      "western/JJ 96\n",
      "familiar/JJ 96\n",
      "constant/JJ 96\n",
      "direct/JJ 93\n",
      "notic/JJ 88\n",
      "current/JJ 87\n",
      "practic/JJ 86\n",
      "special/JJ 84\n",
      "central/JJ 83\n",
      "local/JJ 77\n",
      "low/JJ 76\n",
      "serious/JJ 75\n",
      "same/JJ 75\n",
      "civil/JJ 72\n",
      "french/JJ 69\n",
      "predictable/JJ 64\n",
      "fourth/JJ 62\n",
      "different/JJ 58\n",
      "former/JJ 58\n",
      "overall/JJ 56\n",
      "indian/JJ 56\n",
      "spanish/JJ 56\n",
      "such/JJ 54\n",
      "own/JJ 53\n",
      "narrative/JJ 50\n",
      "superior/JJ 48\n",
      "virtual/JJ 47\n",
      "sudden/JJ 45\n",
      "ridiculous/JJ 44\n",
      "solid/JJ 44\n",
      "fresh/JJ 44\n",
      "hot/JJ 43\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "choose_tagging_texts_two = Counter(choose_tagging_texts2)\n",
    "for word, count in choose_tagging_texts_two.most_common(100):\n",
    "    print(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good/JJ 4619\n",
      "much/JJ 4098\n",
      "great/JJ 2368\n",
      "new/JJ 1719\n",
      "live/JJ 1321\n",
      "bad/JJ 1205\n",
      "last/JJ 1157\n",
      "actual/JJ 1119\n",
      "hard/JJ 1093\n",
      "real/JJ 1083\n",
      "main/JJ 1082\n",
      "old/JJ 1054\n",
      "next/JJ 982\n",
      "final/JJ 832\n",
      "second/JJ 814\n",
      "whole/JJ 784\n",
      "young/JJ 780\n",
      "american/JJ 744\n",
      "short/JJ 742\n",
      "true/JJ 735\n",
      "big/JJ 690\n",
      "high/JJ 598\n",
      "major/JJ 584\n",
      "difficult/JJ 561\n",
      "wrong/JJ 541\n",
      "nice/JJ 525\n",
      "third/JJ 524\n",
      "usual/JJ 497\n",
      "strong/JJ 431\n",
      "small/JJ 425\n",
      "basic/JJ 423\n",
      "full/JJ 419\n",
      "modern/JJ 395\n",
      "certain/JJ 390\n",
      "open/JJ 386\n",
      "overal/JJ 383\n",
      "clear/JJ 375\n",
      "classic/JJ 365\n",
      "total/JJ 355\n",
      "black/JJ 327\n",
      "white/JJ 325\n",
      "dead/JJ 317\n",
      "huge/JJ 310\n",
      "english/JJ 308\n",
      "similar/JJ 307\n",
      "particular/JJ 297\n",
      "recent/JJ 293\n",
      "british/JJ 279\n",
      "due/JJ 272\n",
      "social/JJ 270\n",
      "hous/JJ 268\n",
      "weak/JJ 260\n",
      "complex/JJ 253\n",
      "rich/JJ 251\n",
      "poor/JJ 249\n",
      "overall/JJ 246\n",
      "other/JJ 243\n",
      "common/JJ 242\n",
      "obvious/JJ 241\n",
      "free/JJ 231\n",
      "popular/JJ 229\n",
      "familiar/JJ 226\n",
      "practic/JJ 224\n",
      "current/JJ 217\n",
      "normal/JJ 211\n",
      "central/JJ 209\n",
      "flat/JJ 206\n",
      "german/JJ 197\n",
      "moral/JJ 196\n",
      "red/JJ 190\n",
      "sexual/JJ 185\n",
      "local/JJ 184\n",
      "western/JJ 181\n",
      "former/JJ 177\n",
      "notic/JJ 169\n",
      "civil/JJ 167\n",
      "direct/JJ 166\n",
      "special/JJ 159\n",
      "solid/JJ 147\n",
      "low/JJ 142\n",
      "own/JJ 140\n",
      "tough/JJ 139\n",
      "constant/JJ 135\n",
      "french/JJ 134\n",
      "serious/JJ 133\n",
      "equal/JJ 130\n",
      "stupid/JJ 129\n",
      "fourth/JJ 129\n",
      "predictable/JJ 128\n",
      "russian/JJ 118\n",
      "indian/JJ 117\n",
      "same/JJ 117\n",
      "different/JJ 117\n",
      "fresh/JJ 114\n",
      "superior/JJ 112\n",
      "enjoyable/JJ 105\n",
      "wide/JJ 102\n",
      "european/JJ 101\n",
      "narrative/JJ 99\n",
      "believable/JJ 98\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "choose_tagging_texts_three = Counter(choose_tagging_texts3)\n",
    "for word, count in choose_tagging_texts_three.most_common(100):\n",
    "    print(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good/JJ 9143\n",
      "much/JJ 6500\n",
      "great/JJ 6308\n",
      "new/JJ 3877\n",
      "live/JJ 3539\n",
      "young/JJ 2384\n",
      "old/JJ 2318\n",
      "last/JJ 2226\n",
      "real/JJ 2197\n",
      "next/JJ 2040\n",
      "actual/JJ 1901\n",
      "american/JJ 1882\n",
      "true/JJ 1823\n",
      "hard/JJ 1794\n",
      "main/JJ 1734\n",
      "final/JJ 1613\n",
      "second/JJ 1597\n",
      "bad/JJ 1551\n",
      "short/JJ 1424\n",
      "big/JJ 1292\n",
      "high/JJ 1210\n",
      "whole/JJ 1199\n",
      "nice/JJ 1158\n",
      "small/JJ 1118\n",
      "full/JJ 1101\n",
      "major/JJ 1076\n",
      "difficult/JJ 1047\n",
      "strong/JJ 1013\n",
      "classic/JJ 1008\n",
      "usual/JJ 981\n",
      "modern/JJ 966\n",
      "open/JJ 941\n",
      "third/JJ 855\n",
      "wrong/JJ 850\n",
      "clear/JJ 842\n",
      "english/JJ 793\n",
      "certain/JJ 750\n",
      "white/JJ 746\n",
      "social/JJ 724\n",
      "basic/JJ 722\n",
      "recent/JJ 720\n",
      "total/JJ 659\n",
      "black/JJ 658\n",
      "similar/JJ 652\n",
      "overal/JJ 641\n",
      "british/JJ 638\n",
      "hous/JJ 636\n",
      "complex/JJ 629\n",
      "rich/JJ 627\n",
      "dead/JJ 620\n",
      "particular/JJ 587\n",
      "due/JJ 579\n",
      "familiar/JJ 573\n",
      "current/JJ 559\n",
      "free/JJ 555\n",
      "common/JJ 550\n",
      "other/JJ 530\n",
      "huge/JJ 503\n",
      "civil/JJ 496\n",
      "local/JJ 474\n",
      "practic/JJ 471\n",
      "poor/JJ 467\n",
      "normal/JJ 466\n",
      "popular/JJ 440\n",
      "former/JJ 430\n",
      "own/JJ 416\n",
      "moral/JJ 414\n",
      "western/JJ 404\n",
      "special/JJ 401\n",
      "french/JJ 400\n",
      "obvious/JJ 392\n",
      "overall/JJ 386\n",
      "sexual/JJ 379\n",
      "german/JJ 378\n",
      "direct/JJ 374\n",
      "red/JJ 369\n",
      "weak/JJ 368\n",
      "equal/JJ 356\n",
      "solid/JJ 349\n",
      "notic/JJ 333\n",
      "central/JJ 321\n",
      "indian/JJ 296\n",
      "enjoyable/JJ 291\n",
      "fresh/JJ 285\n",
      "low/JJ 281\n",
      "constant/JJ 259\n",
      "different/JJ 258\n",
      "tough/JJ 256\n",
      "soviet/JJ 254\n",
      "russian/JJ 241\n",
      "spanish/JJ 235\n",
      "wide/JJ 235\n",
      "european/JJ 221\n",
      "unexpect/JJ 218\n",
      "foreign/JJ 216\n",
      "well-written/JJ 207\n",
      "serious/JJ 206\n",
      "legal/JJ 204\n",
      "italian/JJ 198\n",
      "southern/JJ 198\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "choose_tagging_texts_four = Counter(choose_tagging_texts4)\n",
    "for word, count in choose_tagging_texts_four.most_common(100):\n",
    "    print(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great/JJ 16933\n",
      "good/JJ 12820\n",
      "much/JJ 11041\n",
      "live/JJ 7587\n",
      "new/JJ 7349\n",
      "old/JJ 5659\n",
      "young/JJ 4710\n",
      "real/JJ 4467\n",
      "true/JJ 4340\n",
      "last/JJ 4202\n",
      "american/JJ 4134\n",
      "next/JJ 4032\n",
      "hard/JJ 3425\n",
      "actual/JJ 3108\n",
      "classic/JJ 2969\n",
      "final/JJ 2942\n",
      "second/JJ 2801\n",
      "high/JJ 2524\n",
      "whole/JJ 2464\n",
      "full/JJ 2328\n",
      "main/JJ 2304\n",
      "short/JJ 2302\n",
      "big/JJ 2256\n",
      "bad/JJ 2166\n",
      "open/JJ 2024\n",
      "small/JJ 2014\n",
      "modern/JJ 1812\n",
      "white/JJ 1787\n",
      "wrong/JJ 1650\n",
      "difficult/JJ 1627\n",
      "usual/JJ 1623\n",
      "strong/JJ 1565\n",
      "major/JJ 1548\n",
      "clear/JJ 1505\n",
      "black/JJ 1480\n",
      "english/JJ 1468\n",
      "third/JJ 1447\n",
      "nice/JJ 1447\n",
      "rich/JJ 1394\n",
      "total/JJ 1362\n",
      "social/JJ 1346\n",
      "recent/JJ 1335\n",
      "basic/JJ 1235\n",
      "civil/JJ 1141\n",
      "complex/JJ 1138\n",
      "british/JJ 1113\n",
      "free/JJ 1105\n",
      "hous/JJ 1098\n",
      "certain/JJ 1080\n",
      "special/JJ 1067\n",
      "dead/JJ 1055\n",
      "huge/JJ 1025\n",
      "similar/JJ 997\n",
      "practic/JJ 987\n",
      "current/JJ 986\n",
      "particular/JJ 970\n",
      "common/JJ 959\n",
      "familiar/JJ 923\n",
      "poor/JJ 897\n",
      "moral/JJ 889\n",
      "due/JJ 885\n",
      "other/JJ 865\n",
      "normal/JJ 862\n",
      "equal/JJ 816\n",
      "own/JJ 809\n",
      "western/JJ 792\n",
      "popular/JJ 765\n",
      "local/JJ 752\n",
      "red/JJ 687\n",
      "german/JJ 676\n",
      "former/JJ 615\n",
      "direct/JJ 607\n",
      "indian/JJ 585\n",
      "fresh/JJ 568\n",
      "obvious/JJ 558\n",
      "french/JJ 554\n",
      "southern/JJ 551\n",
      "notic/JJ 537\n",
      "central/JJ 517\n",
      "low/JJ 506\n",
      "overal/JJ 491\n",
      "wide/JJ 486\n",
      "spanish/JJ 482\n",
      "unbroken/JJ 480\n",
      "tough/JJ 470\n",
      "sexual/JJ 467\n",
      "soviet/JJ 463\n",
      "different/JJ 453\n",
      "20th/JJ 425\n",
      "grand/JJ 410\n",
      "constant/JJ 399\n",
      "irish/JJ 394\n",
      "safe/JJ 384\n",
      "russian/JJ 378\n",
      "weak/JJ 378\n",
      "alive/JJ 378\n",
      "enjoyable/JJ 373\n",
      "african/JJ 370\n",
      "italian/JJ 367\n",
      "possible/JJ 364\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "choose_tagging_texts_five = Counter(choose_tagging_texts5)\n",
    "for word, count in choose_tagging_texts_five.most_common(100):\n",
    "    print(word,count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
