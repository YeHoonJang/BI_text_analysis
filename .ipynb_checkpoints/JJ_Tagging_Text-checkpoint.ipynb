{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"reviews_Books_5.json\",\"r\") as data_file:\n",
    "    raw_data=data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"AAXUNK0W2DZG5\", \"asin\": \"0060520841\", \"reviewerName\": \"Amazon Customer \\\"leneker\\\"\", \"helpful\": [5, 10], \"reviewText\": \"1996 Bernard Goldberg wrote an editorial for the Wall Street Journal that said there was an obvious bias on the part of network new shows  for the liberal point of view.  he then illustrated this with an example that he dissected in-depth.  The reaction to this observation was the ruination of her career, and the beginning of his status as a pariah among most newsmen.  This book is used to add more ammo to the controversy.That the journalists who so eagerly pry into other peoples lives and business should be reluctant to be examined is hardly surprising.  Almost no one really wants to have his life or business dissected by Mike Wallace not even Dan Rather.  Some facts in this book are really potent such as the survey results which show how the average journalist and the average American are often vastly at odds.  Other chapters highlight different stories that TV news has covered and the analysis that Goldberg has made to point out the liberal bias.  His main theme is that while there is no conspiracy of the left, the fact is that most reporters are liberal but fewer still will admit it.There is some sound reasoning behind this book.  Sadly in execution, it doesn't come off as well as it could.  Goldberg has one argument in all the years he worked closely with Dan Rather (according to him) and yet it seems like all they did was fight.  Why ?  because Goldberg replays that one argument about 5 or 6 times in the book.  Much of the material that is thought provoking the first time around is pretty stale after the third or fourth reading. He kindly reprints the editorial that started the whole furor, too bad this was at the end of the book because the entire first chapter is just a rehash of that argument.  Too often Goldberg is reduced sounding like the bitter vindictive perso 93184\n"
     ]
    }
   ],
   "source": [
    "json_list = []\n",
    "for i in range(len(raw_data)):\n",
    "    try:\n",
    "        json_data = json.loads(raw_data[i])\n",
    "        json_list.append(json_data)\n",
    "    except:\n",
    "        print(raw_data[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = []\n",
    "\n",
    "for i in range(len(json_list)):\n",
    "    review_dict={}\n",
    "    review_dict[\"reviewText\"] = json_list[i][\"reviewText\"]\n",
    "    review_dict[\"overall\"] = json_list[i][\"overall\"]\n",
    "    review_data.append(review_dict)\n",
    "type(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found this book highly interesting. I am not a scholar, so I didn't buy this book to criticize the author (whom I have never heard of). I just happened to pick up the book at the bookstore, read the back cover, some of the pages inside and found it interesting enough for me to read. It is not the best written history thesis I have read, but it is an eye-opener for me.I read some of the reviews briefly and am really glad that I didn't read them until after I finished the book. So, I wanted to point out that I did not buy this book for any other reason other than to learn something new. Whether it is 100% accurate remains to be seen since I am not a historian, but I did find this book thought-provoking, a quick study into what could be a long thesis in the lingering effects of the Black Plague on Western Civilization. A reviewer mentioned that it was focused mostly on English history, which I do agree with but since we are Americans, we are heavily influenced by the British in our law school rooms. Cantor did touch on other issues such as the Jews being blamed for the plague; anthrax is another possibilty for mass deaths that occurred in the Middle Ages; the effect of the Black Death on art, religious thought and scientific studies; the beginnings of the capitalist system that we know today and more.I got the feeling that this book was written as a brief synopsis of what could be a long study. Not only that, I got the impression that this book was written for the lay-men who have little knowledge of history and would like to learn more ... someone like me. While it may be choppy in places and could use a little bit more editing, I still found it interesting. Before I picked up this book, the only thing I know about the plague is that rats are blamed for spreading the disease. I didn't realize that it (Black Death) had such a heavy influence on art, philosophy, religion and more. That alone was fascinating for me and kept me reading through the rest of the book.I didn't buy this book because I am a scholar. I bought this book to learn something new.7/11/09\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_data = random.sample(review_data,len(review_data))\n",
    "random_data = random_data[:10] # 이것만 지우면 됨.\n",
    "print(random_data[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewText = []\n",
    "for i in range(len(random_data)):\n",
    "    reviewText.append(random_data[i][\"reviewText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samsung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from nltk.corpus import stopwords\n",
    ">>> stop = set(stopwords.words('english'))\n",
    ">>> sentence = \"this is a foo bar sentence\"\n",
    ">>> print [i for i in sentence.lower().split() if i not in stop]\n",
    "['foo', 'bar', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have read series many many years ago, still stays all time. unlike sf, protagonists not good, strong nice, mean, selfish, weak a combination those traits. makes some tough reading, particularly first book. be honest, found first book (&#34;the real story&#34;) times repulsive read it anyway end, was real good. inspired me to read next reading became faster better.the story develops intricate plots deeper characters the repulsiveness the first book is not repeated, used a backdrop mutual relations. well considered.so, sit the first book, you will read the rest thoroughly enjoy the last one!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "stopword = []\n",
    "\n",
    "for i in range(len(reviewText)):\n",
    "    split_data = reviewText[i].lower().split()\n",
    "    for j in split_data:\n",
    "        if j in stop:\n",
    "            split_data.remove(j)\n",
    "    stopword.append(split_data)\n",
    "\n",
    "print(\" \".join(stopword[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(stopword)):\n",
    "    for j in stopword[i]:\n",
    "        store = \" \".join(j)\n",
    "    join_stopword.append(store)\n",
    "print(stopword[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "stopword = []\n",
    "##전부\n",
    "for i in range(len(reviewText)):\n",
    "    for j in reviewText[i]:\n",
    "        a = reviewText[i].lower().split()\n",
    "        b = \" \".join(a)\n",
    "        stopword.append(b)\n",
    "    \n",
    "print(stopword[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from nltk.corpus import stopwords\n",
    ">>> stop = set(stopwords.words('english'))\n",
    ">>> sentence = \"this is a foo bar sentence\"\n",
    ">>> print [i for i in sentence.lower().split() if i not in stop]\n",
    "['foo', 'bar', 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stemming = []\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "for i in range(len(stopword)):\n",
    "    a = tokenizer_porter(stopword[i])\n",
    "    b = \" \".join(a)\n",
    "    stemming.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pos_tagging(document):\n",
    "    result = nltk.pos_tag( nltk.word_tokenize(document))    \n",
    "    last_result = ['/'.join(t) for t in result]\n",
    "    return last_result\n",
    "\n",
    "tag = [pos_tagging(i) for i in stemming]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i/NNS', 'have/VBP', 'read/VBN', 'thi/JJ', 'seri/JJ', 'mani/NN', 'mani/CD', 'year/NN', 'ago/RB', ',/,', 'but/CC', 'it/PRP', 'still/RB', 'stay/VB', 'with/IN', 'me/PRP', 'after/IN', 'all/DT', 'that/DT', 'time/NN', './.', 'it/PRP', 'is/VBZ', 'becaus/VBN', 'unlik/JJ', 'most/RBS', 'sf/JJ', ',/,', 'the/DT', 'protagonist/NN', 'are/VBP', 'not/RB', 'good/JJ', ',/,', 'strong/JJ', 'or/CC', 'nice/JJ', ',/,', 'but/CC', 'mean/JJ', ',/,', 'selfish/JJ', ',/,', 'weak/JJ', 'or/CC', 'a/DT', 'combin/NN', 'of/IN', 'those/DT', 'traits/NNS', './.', 'thi/NNS', 'make/VBP', 'for/IN', 'some/DT', 'tough/JJ', 'reading/NN', ',/,', 'particularli/VB', 'the/DT', 'first/JJ', 'book/NN', './.', 'to/TO', 'be/VB', 'honest/JJS', ',/,', 'i/NN', 'found/VBD', 'the/DT', 'first/JJ', 'book/NN', '(/(', '&/CC', '#/#', '34/CD', ';/:', 'the/DT', 'real/JJ', 'story/NN', '&/CC', '#/#', '34/CD', ';/:', ')/)', 'at/IN', 'time/NN', 'repuls/NNS', 'but/CC', 'read/VBP', 'it/PRP', 'anyway/RB', 'until/IN', 'the/DT', 'end/NN', ',/,', 'which/WDT', 'wa/VBP', 'real/JJ', 'good/JJ', './.', 'that/IN', 'inspir/VBZ', 'me/PRP', 'to/TO', 'read/VB', 'the/DT', 'next/JJ', 'and/CC', 'the/DT', 'read/JJ', 'becam/NN', 'faster/RBR', 'and/CC', 'better.th/VB', 'stori/JJR', 'develop/VB', 'more/RBR', 'intric/JJ', 'plot/NN', 'and/CC', 'deeper/JJR', 'charact/NN', 'and/CC', 'the/DT', 'repuls/NN', 'of/IN', 'the/DT', 'first/JJ', 'book/NN', 'is/VBZ', 'not/RB', 'repeated/VBN', ',/,', 'but/CC', 'use/VBP', 'as/IN', 'a/DT', 'backdrop/NN', 'for/IN', 'mutual/JJ', 'relations/NNS', './.', 'well/RB', 'considered.so/RB', ',/,', 'if/IN', 'you/PRP', 'can/MD', 'sit/VB', 'through/IN', 'the/DT', 'first/JJ', 'book/NN', ',/,', 'you/PRP', 'will/MD', 'read/VB', 'the/DT', 'rest/NN', 'and/CC', 'thoroughli/NN', 'enjoy/VBP', 'the/DT', 'last/JJ', 'one/CD', '!/.']\n"
     ]
    }
   ],
   "source": [
    "print(tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagging_JJ = []\n",
    "for i in range(len(tag)):\n",
    "    tagging = []\n",
    "    for j in tag[i]:\n",
    "        if j.split(\"/\")[1] == \"JJ\":\n",
    "            tagging.append(j.split(\"/\")[0])\n",
    "    join_each_tag = \" \".join(tagging)\n",
    "    tagging_JJ.append(join_each_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
